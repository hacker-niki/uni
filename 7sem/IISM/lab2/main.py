import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats

# --- –õ–æ–≥–∏–∫–∞ –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö —Å–ª—É—á–∞–π–Ω—ã—Ö –≤–µ–ª–∏—á–∏–Ω ---

def _chi2_test_continuous(samples, theoretical_dist, n_bins):
    """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∞ —Ö–∏-–∫–≤–∞–¥—Ä–∞—Ç –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
    n = len(samples)
    counts, edges = np.histogram(samples, bins=n_bins)
    exp_counts = np.array([n * (theoretical_dist.cdf(edges[i + 1]) - theoretical_dist.cdf(edges[i]))
                           for i in range(len(counts))])

    obs = counts.astype(float)
    exp = exp_counts.astype(float)

    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –±–∏–Ω–æ–≤ —Å –Ω–∏–∑–∫–æ–π –æ–∂–∏–¥–∞–µ–º–æ–π —á–∞—Å—Ç–æ—Ç–æ–π
    min_exp = 5
    while np.any(exp < min_exp) and len(exp) > 2:
        idx = np.argmin(exp)
        if idx == 0:
            exp[1] += exp[0]
            obs[1] += obs[0]
        else:
            exp[idx - 1] += exp[idx]
            obs[idx - 1] += obs[idx]
        exp = np.delete(exp, idx)
        obs = np.delete(obs, idx)

    if len(exp) <= 2:
        return -1, -1

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è —Ä–∞–≤–µ–Ω—Å—Ç–≤–∞ —Å—É–º–º
    if exp.sum() > 0:
        exp *= obs.sum() / exp.sum()

    # –ò–∑–±–µ–≥–∞–Ω–∏–µ –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å, –µ—Å–ª–∏ exp —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω—É–ª–∏
    if np.any(exp == 0):
        return float('nan'), float('nan')
        
    chi2_stat, p = stats.chisquare(obs, exp)
    return chi2_stat, p


def analyze_continuous_samples(samples, theoretical_dist, name):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—ã–±–æ—Ä–∫—É –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–π –°–í, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≥—Ä–∞—Ñ–∏–∫ –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç."""
    samples = np.asarray(samples)
    fig, ax = plt.subplots(figsize=(8, 5))
    n = len(samples)
    n_bins = max(10, min(100, n // 50))
    ax.hist(samples, bins=n_bins, density=True, alpha=0.7, label='–≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∞—è –ø–ª–æ—Ç–Ω–æ—Å—Ç—å')
    x = np.linspace(np.min(samples), np.max(samples), 1000)

    ax.plot(x, theoretical_dist.pdf(x), 'r-', lw=2, label='–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è –ø–ª–æ—Ç–Ω–æ—Å—Ç—å')
    ax.set_title(f'–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –∏ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è –ø–ª–æ—Ç–Ω–æ—Å—Ç—å ({name})')
    ax.set_xlabel('–ó–Ω–∞—á–µ–Ω–∏–µ')
    ax.set_ylabel('–ü–ª–æ—Ç–Ω–æ—Å—Ç—å')
    ax.legend()
    ax.grid(True, alpha=0.5)
    fig.tight_layout()

    mean = float(np.mean(samples))
    std = float(np.std(samples))
    median = float(np.median(samples))
    se = std / np.sqrt(n)
    t = stats.t.ppf(0.975, n - 1)
    ci_mean = (mean - t * se, mean + t * se)
    sample_var = std ** 2
    chi2_l = stats.chi2.ppf(0.025, n - 1)
    chi2_u = stats.chi2.ppf(0.975, n - 1)
    ci_var = ((n - 1) * sample_var / chi2_u, (n - 1) * sample_var / chi2_l)
    ci_std = (np.sqrt(ci_var[0]), np.sqrt(ci_var[1]))

    ks_stat, ks_p = stats.kstest(samples, theoretical_dist.cdf)
    chi2_stat, chi2_p = _chi2_test_continuous(samples, theoretical_dist, n_bins=n_bins)

    out = []
    out.append(f"–°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó ({name})")
    out.append("=" * 70)
    out.append(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ samples: {n:,}")
    out.append("\n–¢–û–ß–ï–ß–ù–´–ï –û–¶–ï–ù–ö–ò:")
    out.append(f"  –°—Ä–µ–¥–Ω–µ–µ: {mean:.6f}")
    out.append(f"  –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {std:.6f}")
    out.append(f"  –ú–µ–¥–∏–∞–Ω–∞: {median:.6f}")
    out.append("\n–ò–ù–¢–ï–†–í–ê–õ–¨–ù–´–ï –û–¶–ï–ù–ö–ò (95%):")
    out.append(f"  –°—Ä–µ–¥–Ω–µ–µ: ({ci_mean[0]:.6f}, {ci_mean[1]:.6f})")
    out.append(f"  –î–∏—Å–ø–µ—Ä—Å–∏—è: ({ci_var[0]:.6f}, {ci_var[1]:.6f})")
    out.append(f"  –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: ({ci_std[0]:.6f}, {ci_std[1]:.6f})")
    out.append("\n–ü–†–û–í–ï–†–ö–ê –°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø:")
    out.append("  –¢–µ—Å—Ç –ö–æ–ª–º–æ–≥–æ—Ä–æ–≤–∞-–°–º–∏—Ä–Ω–æ–≤–∞:")
    out.append(f"    –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {ks_stat:.6f}")
    out.append(f"    p-value: {ks_p:.6f}")
    out.append(f"    –í—ã–≤–æ–¥: {'–ì–∏–ø–æ—Ç–µ–∑–∞ –Ω–µ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è' if ks_p > 0.05 else '–ì–∏–ø–æ—Ç–µ–∑–∞ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è'}")
    out.append("\n  –¢–µ—Å—Ç —Ö–∏-–∫–≤–∞–¥—Ä–∞—Ç (–ø–æ –±–∏–Ω–∞–º):")
    out.append(f"    –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {chi2_stat:.6f}")
    out.append(f"    p-value: {chi2_p:.6f}")
    out.append(f"    –í—ã–≤–æ–¥: {'–ì–∏–ø–æ—Ç–µ–∑–∞ –Ω–µ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è' if chi2_p > 0.05 else '–ì–∏–ø–æ—Ç–µ–∑–∞ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è'}")

    return fig, "\n".join(out)


# --- –õ–æ–≥–∏–∫–∞ –¥–ª—è –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö —Å–ª—É—á–∞–π–Ω—ã—Ö –≤–µ–ª–∏—á–∏–Ω ---

def _chi2_test_discrete(values, obs_counts, exp_probs, n):
    """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∞ —Ö–∏-–∫–≤–∞–¥—Ä–∞—Ç –¥–ª—è –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
    obs = obs_counts.astype(float).copy()
    exp = (np.array(exp_probs) * n).astype(float)
    
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å –Ω–∏–∑–∫–æ–π –æ–∂–∏–¥–∞–µ–º–æ–π —á–∞—Å—Ç–æ—Ç–æ–π
    min_exp = 5
    while True:
        if len(exp) <= 1: return float('nan'), float('nan')
        min_idx = np.argmin(exp)
        if exp[min_idx] >= min_exp: break
        if min_idx == 0:
            exp[1] += exp[0]
            obs[1] += obs[0]
        else:
            exp[min_idx - 1] += exp[min_idx]
            obs[min_idx - 1] += obs[min_idx]
        exp = np.delete(exp, min_idx)
        obs = np.delete(obs, min_idx)
    
    if exp.sum() > 0:
        exp *= obs.sum() / exp.sum()
    else:
        return float('nan'), float('nan')

    if np.any(exp == 0):
        return float('nan'), float('nan')
    
    chi2_stat, p = stats.chisquare(obs, exp)
    return chi2_stat, p

def analyze_discrete_samples(samples, theoretical_dist, name):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—ã–±–æ—Ä–∫—É –¥–∏—Å–∫—Ä–µ—Ç–Ω–æ–π –°–í, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≥—Ä–∞—Ñ–∏–∫ –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç."""
    samples = np.asarray(samples)
    fig, ax = plt.subplots(figsize=(8, 5))

    unique, counts = np.unique(samples, return_counts=True)
    n = len(samples)
    
    min_val = int(np.min(unique))
    max_val = int(np.max(unique))
    
    values = np.arange(min_val, max_val + 2) # +2 –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏ –≥—Ä–∞—Ñ–∏–∫–∞
    theoretical_probs = theoretical_dist.pmf(values)
    
    empirical_probs_map = {u: c / n for u, c in zip(unique, counts)}
    empirical_probs = np.array([empirical_probs_map.get(v, 0.0) for v in values])

    x = np.arange(len(values))
    width = 0.35
    ax.bar(x - width / 2, theoretical_probs, width, label='–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏', alpha=0.8)
    ax.bar(x + width / 2, empirical_probs, width, label='–≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ —á–∞—Å—Ç–æ—Ç—ã', alpha=0.8)
    ax.set_xlabel('–ó–Ω–∞—á–µ–Ω–∏—è')
    ax.set_ylabel('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å / –ß–∞—Å—Ç–æ—Ç–∞')
    ax.set_title(f'–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏ —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è ({name})')
    ax.set_xticks(x)
    ax.set_xticklabels([str(int(v)) for v in values])
    ax.legend()
    ax.grid(True, axis='y', alpha=0.3)
    fig.tight_layout()

    mean = float(np.mean(samples))
    std = float(np.std(samples))
    median = float(np.median(samples))
    se = std / np.sqrt(n)
    t = stats.t.ppf(0.975, n - 1)
    ci_mean = (mean - t * se, mean + t * se)
    sample_var = std ** 2
    chi2_l = stats.chi2.ppf(0.025, n - 1)
    chi2_u = stats.chi2.ppf(0.975, n - 1)
    ci_var = ((n - 1) * sample_var / chi2_u, (n - 1) * sample_var / chi2_l)
    ci_std = (np.sqrt(ci_var[0]), np.sqrt(ci_var[1]))

    obs_values = np.arange(int(np.min(unique)), int(np.max(unique)) + 1)
    obs_counts = np.array([empirical_probs_map.get(v, 0) * n for v in obs_values])
    exp_probs = theoretical_dist.pmf(obs_values)

    chi2_stat, chi2_p = _chi2_test_discrete(obs_values, obs_counts, exp_probs, n)
    ks_stat, ks_p = stats.kstest(samples, theoretical_dist.cdf)

    out = []
    out.append(f"–°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó ({name})")
    out.append("=" * 70)
    out.append(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ samples: {n:,}")
    out.append("\n–¢–û–ß–ï–ß–ù–´–ï –û–¶–ï–ù–ö–ò:")
    out.append(f"  –°—Ä–µ–¥–Ω–µ–µ: {mean:.6f}")
    out.append(f"  –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {std:.6f}")
    out.append(f"  –ú–µ–¥–∏–∞–Ω–∞: {median:.6f}")
    out.append("\n–ò–ù–¢–ï–†–í–ê–õ–¨–ù–´–ï –û–¶–ï–ù–ö–ò (95%):")
    out.append(f"  –°—Ä–µ–¥–Ω–µ–µ: ({ci_mean[0]:.6f}, {ci_mean[1]:.6f})")
    out.append(f"  –î–∏—Å–ø–µ—Ä—Å–∏—è: ({ci_var[0]:.6f}, {ci_var[1]:.6f})")
    out.append(f"  –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: ({ci_std[0]:.6f}, {ci_std[1]:.6f})")
    out.append("\n–ü–†–û–í–ï–†–ö–ê –°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø:")
    out.append("  –¢–µ—Å—Ç —Ö–∏-–∫–≤–∞–¥—Ä–∞—Ç:")
    if np.isnan(chi2_stat):
        out.append("    –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è —Ç–µ—Å—Ç–∞ —Ö–∏-–∫–≤–∞–¥—Ä–∞—Ç.")
    else:
        out.append(f"    –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {chi2_stat:.6f}")
        out.append(f"    p-value: {chi2_p:.6f}")
        out.append(f"    –í—ã–≤–æ–¥: {'–ì–∏–ø–æ—Ç–µ–∑–∞ –Ω–µ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è' if chi2_p > 0.05 else '–ì–∏–ø–æ—Ç–µ–∑–∞ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è'}")
    out.append("\n  –¢–µ—Å—Ç –ö–æ–ª–º–æ–≥–æ—Ä–æ–≤–∞-–°–º–∏—Ä–Ω–æ–≤–∞ (—Å –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç—å—é –¥–ª—è –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –°–í):")
    out.append(f"    –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {ks_stat:.6f}")
    out.append(f"    p-value: {ks_p:.6f}")
    out.append(f"    –í—ã–≤–æ–¥: {'–ì–∏–ø–æ—Ç–µ–∑–∞ –Ω–µ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è' if ks_p > 0.05 else '–ì–∏–ø–æ—Ç–µ–∑–∞ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è'}")

    return fig, "\n".join(out)


# --- –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å Streamlit ---

st.set_page_config(layout="wide")
st.title("–ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ —Å–ª—É—á–∞–π–Ω—ã—Ö –≤–µ–ª–∏—á–∏–Ω")

# --- –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ ---
st.sidebar.header("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏–º—É–ª—è—Ü–∏–∏")
sim_type = st.sidebar.radio("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –≤–µ–ª–∏—á–∏–Ω—ã", ["–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ", "–î–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ"])

if sim_type == "–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ":
    dist_name = st.sidebar.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:",
        ["–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ", "–ù–æ—Ä–º–∞–ª—å–Ω–æ–µ", "–†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ", "–õ–æ–≥–Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ"]
    )
    if dist_name == "–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ":
        lam = st.sidebar.number_input("–ü–∞—Ä–∞–º–µ—Ç—Ä Œª (–∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å)", value=1.0, min_value=0.01, format="%.2f")
    elif dist_name == "–ù–æ—Ä–º–∞–ª—å–Ω–æ–µ":
        mu = st.sidebar.number_input("Œº (–º–∞—Ç. –æ–∂–∏–¥–∞–Ω–∏–µ)", value=0.0, format="%.2f")
        sigma = st.sidebar.number_input("œÉ (—Å—Ç–∞–Ω–¥. –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ)", value=1.0, min_value=0.01, format="%.2f")
    elif dist_name == "–†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ":
        a = st.sidebar.number_input("a (–Ω–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞)", value=0.0, format="%.2f")
        b = st.sidebar.number_input("b (–≤–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞)", value=1.0, format="%.2f")
    elif dist_name == "–õ–æ–≥–Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ":
        mu = st.sidebar.number_input("Œº (–º–∞—Ç. –æ–∂–∏–¥–∞–Ω–∏–µ –ª–æ–≥–∞—Ä–∏—Ñ–º–∞)", value=0.0, format="%.2f")
        sigma = st.sidebar.number_input("œÉ (—Å—Ç–∞–Ω–¥. –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –ª–æ–≥–∞—Ä–∏—Ñ–º–∞)", value=1.0, min_value=0.01, format="%.2f")

else: # –î–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ
    dist_name = st.sidebar.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:",
        ["–ë–∏–Ω–æ–º–∏–∞–ª—å–Ω–æ–µ", "–ü—É–∞—Å—Å–æ–Ω–∞", "–ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–µ"]
    )
    if dist_name == "–ë–∏–Ω–æ–º–∏–∞–ª—å–Ω–æ–µ":
        trials = st.sidebar.number_input("n (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø—ã—Ç–∞–Ω–∏–π)", value=10, min_value=1, step=1)
        p_binom = st.sidebar.slider("p (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞)", 0.0, 1.0, 0.5)
    elif dist_name == "–ü—É–∞—Å—Å–æ–Ω–∞":
        lam_poisson = st.sidebar.number_input("Œª (–∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å)", value=3.0, min_value=0.1, format="%.2f")
    elif dist_name == "–ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–µ":
        p_geom = st.sidebar.slider("p (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞)", 0.0, 1.0, 0.3)

n_samples = st.sidebar.number_input("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ samples", value=10000, min_value=10, step=100)

run_button = st.sidebar.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–∏–º—É–ª—è—Ü–∏—é")


# --- –û—Å–Ω–æ–≤–Ω–æ–µ –æ–∫–Ω–æ –¥–ª—è –≤—ã–≤–æ–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---
if run_button:
    try:
        u = np.random.random(n_samples) # –ë–∞–∑–æ–≤–∞—è —Å–ª—É—á–∞–π–Ω–∞—è –≤–µ–ª–∏—á–∏–Ω–∞

        if sim_type == "–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ":
            if dist_name == "–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ":
                if lam <= 0: raise ValueError("Œª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å > 0")
                samples = -np.log(1 - u) / lam
                theoretical = stats.expon(scale=1.0 / lam)
            elif dist_name == "–ù–æ—Ä–º–∞–ª—å–Ω–æ–µ":
                if sigma <= 0: raise ValueError("œÉ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å > 0")
                samples = stats.norm.ppf(u, loc=mu, scale=sigma)
                theoretical = stats.norm(loc=mu, scale=sigma)
            elif dist_name == "–†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ":
                if a >= b: raise ValueError("a –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å < b")
                samples = a + (b - a) * u
                theoretical = stats.uniform(loc=a, scale=b - a)
            elif dist_name == "–õ–æ–≥–Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ":
                if sigma <= 0: raise ValueError("œÉ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å > 0")
                z = stats.norm.ppf(u)
                samples = np.exp(mu + sigma * z)
                theoretical = stats.lognorm(s=sigma, scale=np.exp(mu))
            
            fig, results_text = analyze_continuous_samples(samples, theoretical, dist_name)

        else: # –î–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ
            if dist_name == "–ë–∏–Ω–æ–º–∏–∞–ª—å–Ω–æ–µ":
                if not (0 <= p_binom <= 1): raise ValueError("p –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ [0,1]")
                samples = stats.binom.ppf(u, n=trials, p=p_binom).astype(int)
                theoretical = stats.binom(n=trials, p=p_binom)
            elif dist_name == "–ü—É–∞—Å—Å–æ–Ω–∞":
                if lam_poisson <= 0: raise ValueError("Œª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å > 0")
                samples = stats.poisson.ppf(u, mu=lam_poisson).astype(int)
                theoretical = stats.poisson(mu=lam_poisson)
            elif dist_name == "–ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–µ":
                if not (0 < p_geom <= 1): raise ValueError("p –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ (0,1]")
                samples = stats.geom.ppf(u, p=p_geom).astype(int)
                theoretical = stats.geom(p=p_geom)

            fig, results_text = analyze_discrete_samples(samples, theoretical, dist_name)

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        tab1, tab2 = st.tabs(["üìä –ì—Ä–∞—Ñ–∏–∫", "üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞"])
        with tab1:
            st.pyplot(fig)
        with tab2:
            st.text(results_text)
            
    except Exception as e:
        st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")

else:
    st.info("–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ –∏ –Ω–∞–∂–º–∏—Ç–µ '–ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–∏–º—É–ª—è—Ü–∏—é'.")
