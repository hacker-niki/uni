import numpy as np

# Исходные данные задачи квадратичного программирования
c = np.array([-8, -6, -3, -6])  # Вектор коэффициентов линейной части целевой функции f(x) = c^T x + (1/2) x^T D x
D = np.array([                  # Симметричная матрица D для квадратичной части целевой функции, положительно полуопределённая
    [2, 1, 1, 0],
    [1, 1, 0, 0],
    [1, 0, 1, 0],
    [0, 0, 0, 0]
])
A = np.array([                  # Матрица ограничений A для равенств A x = b
    [1, 0, 2, 1],
    [0, 1, -1, 2]
])
b = np.array([2, 3])            # Вектор правых частей ограничений A x = b

# Начальный допустимый план и опорные множества
x = np.array([2, 3, 0, 0])      # Начальный план x, удовлетворяющий A x = b и x >= 0
Jb = [0, 1]                     # Опорное множество Jb — индексы базисных переменных, |Jb| = rank(A)
Jb_star = [0, 1]                # Расширенное опорное множество Jb* — включает Jb и дополнительные индексы

# Основной цикл метода
while True:
    # Шаг 1: Вычисляем вспомогательные векторы
    cx = c + D @ x              # Вектор c(x) = c + D x — градиент целевой функции в точке x
    Ab = A[:, Jb]               # Матрица Ab — подматрица A, содержащая столбцы с индексами из Jb (должна быть обратимой)
    cb = cx[Jb]                 # Вектор cb — компоненты c(x) для базисных индексов Jb

    # Вычисляем вектор потенциалов u
    u = -np.linalg.inv(Ab) @ cb # u = -Ab^(-1) cb — вектор потенциалов для проверки оптимальности

    # Вычисляем вектор Δ(x) — индикатор направления улучшения
    delta = u @ A + cx          # Δ(x) = u A + c(x) — показывает, как можно уменьшить f(x)
    delta[Jb_star] = 0          # Для индексов из Jb* Δ(x) обнуляем, так как эти переменные уже учтены в базисе

    # Шаг 2: Проверка условия оптимальности
    if np.all(delta >= 0):      # Если все Δ(x) >= 0, текущий план x оптимален
        print("Оптимальное решение найдено:", x)
        break                   # Выход из цикла, решение найдено

    # Шаг 3: Выбор направления улучшения
    j0 = np.argmin(delta)       # Индекс j0 — минимальная отрицательная компонента Δ(x), указывает, какую переменную ввести

    # Шаг 4: Построение вектора направления l
    # Формируем блочную матрицу H для вычисления направления спуска
    H = np.block([
        [D[np.ix_(Jb_star, Jb_star)], A[:, Jb_star].T],  # Верхняя часть: D для Jb* и A^T для Jb*
        [A[:, Jb_star], np.zeros((A.shape[0], A.shape[0]))]  # Нижняя часть: A для Jb* и нули
    ])
    H_inv = np.linalg.inv(H)    # Обратная матрица H^(-1), нужна для решения системы уравнений

    # Вектор b* — комбинация столбцов D и A для индекса j0
    b_star = np.hstack((D[:, j0][Jb_star], A[:, j0]))  # b* = [D[:, j0] для Jb*; A[:, j0]]

    # Вычисляем вектор l — направление спуска
    l = -H_inv @ b_star         # l = -H^(-1) b* — решение системы для поиска направления
    ljb_star = l[:len(Jb_star)] # Компоненты l для индексов из Jb*

    # Формируем полный вектор l
    l_full = np.zeros_like(x)   # Создаём нулевой вектор размером с x
    l_full[Jb_star] = ljb_star  # Заполняем значениями l для индексов Jb*
    l_full[j0] = 1              # Для индекса j0 ставим 1 (переменная вводится в базис)

    # Шаг 5: Определяем шаг theta — насколько далеко можно двигаться по направлению l
    delta_j0 = delta[j0]        # Значение Δ(x) в точке j0
    sigma = l_full @ D @ l_full # sigma = l^T D l — мера кривизны целевой функции вдоль l

    if sigma > 0:               # Если sigma > 0, вычисляем конечный шаг theta_j0
        theta_j0 = abs(delta_j0) / sigma  # theta_j0 = |Δ_j0| / sigma
    else:                       # Если sigma <= 0, шаг неограничен
        theta_j0 = np.inf

    # Вычисляем theta для индексов из Jb*, ограничивающих движение
    theta_j = np.array([-x[j] / l_full[j] if l_full[j] < 0 else np.inf for j in Jb_star])
                                # theta_j = -x[j] / l[j], если l[j] < 0, иначе бесконечность

    # Находим минимальный шаг theta_min
    theta_min = min(*theta_j, theta_j0)  # theta_min — минимальное значение среди всех theta

    # Проверка на неограниченность целевой функции
    if theta_min == np.inf:     # Если theta_min бесконечно, f(x) не ограничена снизу
        print("Целевая функция задачи не ограничена снизу на множестве допустимых планов")
        break                   # Выход из цикла

    # Шаг 6: Обновляем текущий план x
    x = x + theta_min * l_full  # Новый план: x = x + theta_min * l

    # Обновляем опорные множества Jb и Jb*
    j_star = np.argmin(np.hstack((theta_j, [theta_j0])))  # Индекс, где достигается theta_min
    if j_star == len(theta_j):  # Если минимум достигается на theta_j0
        Jb_star.append(j0)      # Добавляем j0 в Jb* (новая переменная входит в расширенный базис)
    elif Jb_star[j_star] in Jb: # Если j_star в Jb (базисная переменная)
        Jb[Jb.index(Jb_star[j_star])] = j0  # Заменяем j_star на j0 в Jb
    else:                       # Если j_star в Jb*, но не в Jb
        Jb_star.remove(Jb_star[j_star])  # Удаляем j_star из Jb*